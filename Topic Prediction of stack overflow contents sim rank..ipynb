{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"content_topic_prediction/Topic_prediction_data_train.txt\",sep='\\t',header=None)\n",
    "data.columns = ['text','uid','type','timestamp']\n",
    "labels = pd.read_csv(\"content_topic_prediction/Topic_prediction_labels_train.txt\",sep='\\t',header=None)\n",
    "labels.columns = ['label']\n",
    "data['label'] = labels['label']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>uid</th>\n",
       "      <th>type</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>distinct consubstanti translat roman missal pu...</td>\n",
       "      <td>0</td>\n",
       "      <td>Q</td>\n",
       "      <td>0.01</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cathol christian power bind loos catholic beli...</td>\n",
       "      <td>0</td>\n",
       "      <td>Q</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>read scriptur common worship christian church ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Q</td>\n",
       "      <td>0.01</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>accord person polit libertarian compat golden ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Q</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>criteria cathol determin testament charact pre...</td>\n",
       "      <td>0</td>\n",
       "      <td>Q</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  uid type  timestamp  \\\n",
       "0  distinct consubstanti translat roman missal pu...    0    Q       0.01   \n",
       "1  cathol christian power bind loos catholic beli...    0    Q       0.01   \n",
       "2  read scriptur common worship christian church ...    0    Q       0.01   \n",
       "3  accord person polit libertarian compat golden ...    0    Q       0.01   \n",
       "4  criteria cathol determin testament charact pre...    0    Q       0.01   \n",
       "\n",
       "   label  \n",
       "0      9  \n",
       "1      0  \n",
       "2      9  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98116, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[(data['text'].notnull())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96269, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=data.reset_index(drop=True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer = \"word\",   \n",
    "                             tokenizer = None,    \n",
    "                             preprocessor = None, \n",
    "                             stop_words = None,   \n",
    "                             max_features = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_features = vectorizer.fit_transform(data[\"text\"])\n",
    "features= np.array(train_data_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = LogisticRegression(random_state=1)\n",
    "#classifier= GradientBoostingClassifier()\n",
    "#classifier= GaussianNB()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95306, 5000) (963, 5000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "# scores = cross_val_score(classifier, train_data_features, data[\"label\"], cv=3)\n",
    "x_Train, x_Test, y_Train,  y_Test= train_test_split(train_data_features,data[\"label\"], test_size=.01)\n",
    "clf= classifier.fit(x_Train,y_Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_f=[\"hello this is a good day\",\"nice day this is\", \"hello how are you\", \"hello how are you today\", \"batman wins all\", \"hey how are you\"]\n",
    "corpus = pd.DataFrame(columns=[\"ftext\"])\n",
    "corpus[\"ftext\"] = text_f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ftext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hello this is a good day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nice day this is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hello how are you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hello how are you today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>batman wins all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hey how are you</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      ftext\n",
       "0  hello this is a good day\n",
       "1          nice day this is\n",
       "2         hello how are you\n",
       "3   hello how are you today\n",
       "4           batman wins all\n",
       "5           hey how are you"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ftext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hello this is a good day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nice day this is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hello how are you today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>batman wins all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hey how are you</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      ftext\n",
       "0  hello this is a good day\n",
       "1          nice day this is\n",
       "2   hello how are you today\n",
       "3           batman wins all\n",
       "4           hey how are you"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kkl=corpus.drop([2])\n",
    "kkl = kkl.reset_index(drop=True)\n",
    "kkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ftext    hello how are you today\n",
       "Name: 3, dtype: object"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kkl.iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfVect= TfidfVectorizer(min_df=0.0010, ngram_range=[1,3]).fit_transform(data[\"text\"]).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfVect=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96269, 7578)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfVect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "import operator\n",
    "\n",
    "\n",
    "def sim_rank(tx_id,tf_corpus, top=3):\n",
    "    all_score={}\n",
    "    \n",
    "    for i in range(len(tf_corpus)):\n",
    "        if i==tx_id:\n",
    "            #print(data.iloc[i][\"text\"])\n",
    "            continue\n",
    "        score= result = 1 - spatial.distance.cosine(tf_corpus[tx_id], tf_corpus[i])\n",
    "        all_score[i] = score\n",
    "    sorted_scores = sorted(all_score.items(), key=operator.itemgetter(1))\n",
    "    sorted_scores.reverse()\n",
    "    \n",
    "#     print(data[\"text\"][tx_id])\n",
    "#     print(data[\"text\"][sorted_scores[0][0]])\n",
    "#     print(data[\"text\"][sorted_scores[1][0]])\n",
    "#     print(data[\"text\"][sorted_scores[2][0]])\n",
    "    return sorted_scores[0:top]\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fallen angel redeem bibl devil fallen angel creat good chose join lucif rebel consequ lost place heaven angel save angel remain choos chang side thing salvat angel\n"
     ]
    }
   ],
   "source": [
    "all_ranks=sim_rank(353,tfVect,top=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fallen', 'angel', 'redeem', 'bibl', 'devil', 'fallen', 'angel', 'creat', 'good', 'chose', 'join', 'lucif', 'rebel', 'consequ', 'lost', 'place', 'heaven', 'angel', 'save', 'angel', 'remain', 'choos', 'chang', 'side', 'thing', 'salvat', 'angel'] 27\n"
     ]
    }
   ],
   "source": [
    "l1=data[\"text\"][353].split(\" \")\n",
    "\n",
    "print(l1, len(l1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bibl', 'devil', 'fallen', 'angel', 'creat', 'good', 'chose', 'join', 'lucif', 'rebel', 'consequ', 'lost', 'place', 'heaven', 'angel', 'save', 'angel', 'remain', 'choos', 'chang', 'side', 'thing', 'salvat', 'angel'] 24\n"
     ]
    }
   ],
   "source": [
    "l2=data[\"text\"][79261].split(\" \")\n",
    "print(l2, len(l2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['heaven', 'save', 'lost', 'angel', 'rebel', 'good', 'bibl', 'consequ', 'thing', 'place', 'side', 'choos', 'chang', 'fallen', 'chose', 'salvat', 'join', 'devil', 'creat', 'lucif', 'remain']\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "print(list(set(l1).intersection(l2)))\n",
    "print(len(list(set(l1).intersection(l2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'differ type cathol christian call roman cathol actual latin rite cathol eastern orthodox made rest call latin rite eastern rite older'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"text\"][15969]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[1][\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(74840, 1.0), (72516, 1.0), (79261, 0.9676458882544372), (1989, 0.7354877758670498), (88353, 0.6922723154639895), (61574, 0.677995199001079), (64653, 0.6571531322849749), (3728, 0.6318239394250972), (19678, 0.6189904721698241), (19680, 0.6169877132252042), (35426, 0.6136494253746404), (92248, 0.6017633128070966), (92247, 0.5874486592304566), (16299, 0.5697745311797408), (42641, 0.5563792643758267), (56131, 0.5522454016664318), (57539, 0.5420826163803141), (44082, 0.5381335830135789), (290, 0.5303476883100257), (70384, 0.5261336147738995), (9090, 0.5227128550531639), (20737, 0.5144285573837044), (85958, 0.5141667439807481), (77223, 0.5141667439807481), (47296, 0.5131008298213231), (59058, 0.5128983371786783), (14256, 0.5114020692793712), (37093, 0.510058656133014), (30383, 0.5066956266309778), (2246, 0.5012466768121568), (55643, 0.4998145458516212), (75423, 0.49784045179539804), (4681, 0.49784045179539804), (62286, 0.4965798189883486), (19682, 0.49427915176566184), (19530, 0.4929372321515576), (50866, 0.488642740560597), (6403, 0.4867379831429619), (83450, 0.4828080323095362), (15248, 0.4828080323095362), (76224, 0.4827930221727007), (75983, 0.4827930221727007), (75760, 0.4827930221727007), (75721, 0.4827930221727007), (74374, 0.4827930221727007), (73108, 0.4827930221727007), (72437, 0.4827930221727007), (1121, 0.4827930221727007), (11806, 0.4814375324453788), (19656, 0.4813397921105853)]\n"
     ]
    }
   ],
   "source": [
    "all_ranked_labels=[]\n",
    "print(all_ranks)\n",
    "for k in range(len(all_ranks)):\n",
    "    \n",
    "    all_ranked_labels.append(data.iloc[all_ranks[k][0]][\"label\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 8,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 8,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 0]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ranked_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([8, 0, 2, 3])\n",
      "dict_values([3, 13, 17, 17])\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(Counter(all_ranked_labels).keys())\n",
    "print(Counter(all_ranked_labels).values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x5000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 49 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.predict(x_Test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sim_score(tx_id,tf_corpus, top=3):\n",
    "    #print(\"true label - {0}\".format(data.iloc[tx_id][\"label\"]))\n",
    "    trueL= data.iloc[tx_id][\"label\"]\n",
    "    all_ranks=sim_rank(tx_id,tfVect,top=top)\n",
    "     \n",
    "    all_ranked_labels=[]\n",
    "    cumu_scores={}\n",
    "    for k in range(len(all_ranks)):\n",
    "        if data.iloc[all_ranks[k][0]][\"label\"] not in cumu_scores:\n",
    "            cumu_scores[data.iloc[all_ranks[k][0]][\"label\"]] = all_ranks[k][1]\n",
    "        else:\n",
    "            cumu_scores[data.iloc[all_ranks[k][0]][\"label\"]] = cumu_scores[data.iloc[all_ranks[k][0]][\"label\"]] + all_ranks[k][1]\n",
    "           \n",
    "        all_ranked_labels.append(data.iloc[all_ranks[k][0]][\"label\"])\n",
    "        keys= Counter(all_ranked_labels).keys()\n",
    "        vals= Counter(all_ranked_labels).values()\n",
    "   \n",
    "#     print(all_ranks)\n",
    "    finalscore= sorted(cumu_scores.items(), key=operator.itemgetter(1))\n",
    "    finalscore.reverse()\n",
    "    #print(\"Predicted label- {0}\".format(finalscore[0]))\n",
    "    #print(cumu_scores, keys, vals) \n",
    "    return trueL, finalscore[0][0]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bibl talk wine alcohol wine discuss past accept christian drink alcohol heard dri believ wine bibl wine common today actual alcohol grape juic person believ wine jesus day wine biblic histor evid contrari wine past ferment juic\n",
      "Predicted label- (9, 24.484298493779182)\n",
      "{0: 6.761262313498027, 9: 24.484298493779182} dict_keys([0, 9]) dict_values([12, 38])\n"
     ]
    }
   ],
   "source": [
    "tl, pl=sim_score(400,tfVect,top=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 9\n"
     ]
    }
   ],
   "source": [
    "print(tl,pl[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration -0 at 2018-11-19 22:17:13.192874\n",
      "iteration -1 at 2018-11-19 22:17:42.741864\n",
      "iteration -2 at 2018-11-19 22:18:13.886592\n",
      "iteration -3 at 2018-11-19 22:18:44.334181\n",
      "iteration -4 at 2018-11-19 22:19:13.104273\n",
      "iteration -5 at 2018-11-19 22:19:43.894945\n",
      "iteration -6 at 2018-11-19 22:20:17.272706\n",
      "iteration -7 at 2018-11-19 22:20:48.227935\n",
      "iteration -8 at 2018-11-19 22:21:18.111038\n",
      "iteration -9 at 2018-11-19 22:21:49.368459\n",
      "iteration -10 at 2018-11-19 22:22:19.256544\n",
      "iteration -11 at 2018-11-19 22:22:49.265348\n",
      "iteration -12 at 2018-11-19 22:23:19.452602\n",
      "iteration -13 at 2018-11-19 22:23:47.544580\n",
      "iteration -14 at 2018-11-19 22:24:15.917714\n",
      "iteration -15 at 2018-11-19 22:24:45.804802\n",
      "iteration -16 at 2018-11-19 22:25:14.693597\n",
      "iteration -17 at 2018-11-19 22:25:44.036145\n",
      "iteration -18 at 2018-11-19 22:26:13.645933\n",
      "iteration -19 at 2018-11-19 22:26:43.251816\n",
      "iteration -20 at 2018-11-19 22:27:05.307833\n",
      "iteration -21 at 2018-11-19 22:27:35.509120\n",
      "iteration -22 at 2018-11-19 22:28:01.024857\n",
      "iteration -23 at 2018-11-19 22:28:35.538573\n",
      "iteration -24 at 2018-11-19 22:29:05.422687\n",
      "iteration -25 at 2018-11-19 22:29:33.871904\n",
      "iteration -26 at 2018-11-19 22:30:03.055776\n",
      "iteration -27 at 2018-11-19 22:30:33.193234\n",
      "iteration -28 at 2018-11-19 22:31:06.656759\n",
      "iteration -29 at 2018-11-19 22:31:43.645856\n",
      "iteration -30 at 2018-11-19 22:32:19.765245\n",
      "iteration -31 at 2018-11-19 22:33:08.087384\n",
      "iteration -32 at 2018-11-19 22:33:52.921743\n",
      "iteration -33 at 2018-11-19 22:34:40.354918\n",
      "iteration -34 at 2018-11-19 22:35:16.189666\n",
      "iteration -35 at 2018-11-19 22:35:49.688099\n",
      "iteration -36 at 2018-11-19 22:36:26.168633\n",
      "iteration -37 at 2018-11-19 22:37:14.981159\n",
      "iteration -38 at 2018-11-19 22:38:02.980507\n",
      "iteration -39 at 2018-11-19 22:38:49.200809\n",
      "iteration -40 at 2018-11-19 22:39:44.689058\n",
      "iteration -41 at 2018-11-19 22:40:32.853923\n",
      "iteration -42 at 2018-11-19 22:41:18.180036\n",
      "iteration -43 at 2018-11-19 22:42:04.351015\n",
      "iteration -44 at 2018-11-19 22:42:56.168545\n",
      "iteration -45 at 2018-11-19 22:43:45.563578\n",
      "iteration -46 at 2018-11-19 22:44:33.577613\n",
      "iteration -47 at 2018-11-19 22:45:21.343258\n",
      "iteration -48 at 2018-11-19 22:46:13.405764\n",
      "iteration -49 at 2018-11-19 22:46:54.962132\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "labelt=[]\n",
    "labelp=[]\n",
    "for i in range(50):\n",
    "    print(\"iteration -{0} at {1}\".format(i, datetime.datetime.now()))\n",
    "    tl, pl=sim_score(i,tfVect,top=50)\n",
    "    labelt.append(tl)\n",
    "    labelp.append(pl)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration -35000 at 2018-11-20 19:20:04.791589\n",
      "iteration -35001 at 2018-11-20 19:20:40.101350\n",
      "iteration -35002 at 2018-11-20 19:21:14.359753\n",
      "iteration -35003 at 2018-11-20 19:21:46.422023\n",
      "iteration -35004 at 2018-11-20 19:22:18.570065\n",
      "iteration -35005 at 2018-11-20 19:22:54.659570\n",
      "iteration -35006 at 2018-11-20 19:23:33.908625\n",
      "iteration -35007 at 2018-11-20 19:24:12.574242\n",
      "iteration -35008 at 2018-11-20 19:24:49.194327\n",
      "iteration -35009 at 2018-11-20 19:25:28.561069\n",
      "iteration -35010 at 2018-11-20 19:26:14.541128\n",
      "iteration -35011 at 2018-11-20 19:27:03.439385\n",
      "iteration -35012 at 2018-11-20 19:27:46.325727\n",
      "iteration -35013 at 2018-11-20 19:28:35.695756\n",
      "iteration -35014 at 2018-11-20 19:29:07.234426\n",
      "iteration -35015 at 2018-11-20 19:29:38.245509\n",
      "iteration -35016 at 2018-11-20 19:30:08.728021\n",
      "iteration -35017 at 2018-11-20 19:30:40.217808\n",
      "iteration -35018 at 2018-11-20 19:31:10.616734\n",
      "iteration -35019 at 2018-11-20 19:31:40.743129\n",
      "iteration -35020 at 2018-11-20 19:32:10.530484\n",
      "iteration -35021 at 2018-11-20 19:32:43.313067\n",
      "iteration -35022 at 2018-11-20 19:33:11.726945\n",
      "iteration -35023 at 2018-11-20 19:33:39.607359\n",
      "iteration -35024 at 2018-11-20 19:34:09.087532\n",
      "iteration -35025 at 2018-11-20 19:34:39.462317\n",
      "iteration -35026 at 2018-11-20 19:35:11.269286\n",
      "iteration -35027 at 2018-11-20 19:35:40.523054\n",
      "iteration -35028 at 2018-11-20 19:36:10.544783\n",
      "iteration -35029 at 2018-11-20 19:36:45.149898\n",
      "iteration -35030 at 2018-11-20 19:37:18.228466\n",
      "iteration -35031 at 2018-11-20 19:37:47.627879\n",
      "iteration -35032 at 2018-11-20 19:38:17.551869\n",
      "iteration -35033 at 2018-11-20 19:38:49.066605\n",
      "iteration -35034 at 2018-11-20 19:39:19.868368\n",
      "iteration -35035 at 2018-11-20 19:39:50.225080\n",
      "iteration -35036 at 2018-11-20 19:40:20.339558\n",
      "iteration -35037 at 2018-11-20 19:40:52.641192\n",
      "iteration -35038 at 2018-11-20 19:41:22.334795\n",
      "iteration -35039 at 2018-11-20 19:41:52.852218\n",
      "iteration -35040 at 2018-11-20 19:42:24.636214\n",
      "iteration -35041 at 2018-11-20 19:42:56.810189\n",
      "iteration -35042 at 2018-11-20 19:43:27.881110\n",
      "iteration -35043 at 2018-11-20 19:43:58.092371\n",
      "iteration -35044 at 2018-11-20 19:44:28.069219\n",
      "iteration -35045 at 2018-11-20 19:44:58.041167\n",
      "iteration -35046 at 2018-11-20 19:45:28.875727\n",
      "iteration -35047 at 2018-11-20 19:45:59.950639\n",
      "iteration -35048 at 2018-11-20 19:46:27.686482\n",
      "iteration -35049 at 2018-11-20 19:46:58.201070\n"
     ]
    }
   ],
   "source": [
    "#Take random ranges of documents to predict.\n",
    "for i in range(35000, 35050):\n",
    "    print(\"iteration -{0} at {1}\".format(i, datetime.datetime.now()))\n",
    "    tl, pl=sim_score(i,tfVect,top=50)\n",
    "    labelt.append(tl)\n",
    "    labelp.append(pl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "271"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labelt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5856697819314641"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, f1_score,recall_score, accuracy_score\n",
    "accuracy_score(labelt, labelp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
